{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
        "Min-Max scaling is a data preprocessing technique that transforms features to a specific range, typically [0, 1] or [-1, 1], using the formula:\n",
        "X_scaled = (X - X_min) / (X_max - X_min)\n",
        "This ensures that all features are on the same scale, which is important for machine learning algorithms sensitive to feature magnitude, such as gradient descent and distance-based methods.\n",
        "\n",
        "Example:\n",
        "If a feature has values [10, 20, 30, 40, 50] and you want to scale it to [0, 1]:\n",
        "- X_min = 10, X_max = 50\n",
        "- Transformed values: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
        "Unit Vector scaling (or normalization) scales each data point to have a unit norm (length of 1) using the formula:\n",
        "X_scaled = X / ||X||\n",
        "where ||X|| is the Euclidean norm.\n",
        "\n",
        "Difference from Min-Max scaling:\n",
        "- Min-Max scaling maps values to a specific range, whereas Unit Vector scaling focuses on the direction and magnitude of vectors.\n",
        "- Unit Vector scaling is often used for text data and cosine similarity.\n",
        "\n",
        "Example:\n",
        "For a vector [3, 4]:\n",
        "- ||X|| = sqrt(3^2 + 4^2) = 5\n",
        "- Scaled vector: [3/5, 4/5] = [0.6, 0.8]\n",
        "\n",
        "Q3. What is PCA (Principal Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
        "Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms features into a smaller number of uncorrelated components while retaining as much variance as possible. The principal components are linear combinations of the original features, ranked by the amount of variance they capture.\n",
        "\n",
        "Example:\n",
        "For a dataset with 10 correlated features, PCA might identify that 3 principal components capture 95% of the variance. These 3 components can replace the original 10 features, reducing dimensionality and computational cost.\n",
        "\n",
        "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
        "PCA performs feature extraction by creating new features (principal components) that summarize the original features. Unlike feature selection, which selects a subset of existing features, PCA generates a new feature space optimized for variance representation.\n",
        "\n",
        "Example:\n",
        "If a dataset contains features [height, weight, age], PCA might produce components like:\n",
        "- PC1: captures overall size.\n",
        "- PC2: captures the age-related variability.\n",
        "These components serve as extracted features for modeling.\n",
        "\n",
        "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
        "1. Collect data: Gather features such as price (in dollars), rating (out of 5), and delivery time (in minutes).\n",
        "2. Identify range: Find the minimum and maximum values for each feature.\n",
        "   - Price: [5, 100], Rating: [1, 5], Delivery Time: [10, 60].\n",
        "3. Apply Min-Max scaling:\n",
        "   - Scale price, rating, and delivery time to [0, 1] using the formula.\n",
        "   - Example: A record with price = 50, rating = 4, and delivery time = 30 would scale to:\n",
        "     - Price: (50 - 5) / (100 - 5) = 0.4737\n",
        "     - Rating: (4 - 1) / (5 - 1) = 0.75\n",
        "     - Delivery Time: (30 - 10) / (60 - 10) = 0.4\n",
        "\n",
        "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
        "1. Standardize features: Normalize all features to have zero mean and unit variance.\n",
        "2. Compute covariance matrix: Calculate the covariance matrix of the standardized features.\n",
        "3. Perform eigen decomposition: Extract eigenvalues and eigenvectors to determine the principal components.\n",
        "4. Select components: Choose the top principal components that explain most of the variance (e.g., 95%).\n",
        "5. Transform dataset: Project the original data onto the selected principal components to obtain a reduced feature set.\n",
        "\n",
        "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n",
        "1. Identify min and max values:\n",
        "   - X_min = 1, X_max = 20\n",
        "2. Apply Min-Max scaling formula to map to [-1, 1]:\n",
        "X_scaled = (2 * (X - X_min) / (X_max - X_min)) - 1\n",
        "3. Transform values:\n",
        "   - For 1: (2 * (1 - 1) / (20 - 1)) - 1 = -1\n",
        "   - For 5: (2 * (5 - 1) / (20 - 1)) - 1 = -0.789\n",
        "   - For 10: (2 * (10 - 1) / (20 - 1)) - 1 = -0.368\n",
        "   - For 15: (2 * (15 - 1) / (20 - 1)) - 1 = 0.263\n",
        "   - For 20: (2 * (20 - 1) / (20 - 1)) - 1 = 1\n",
        "\n",
        "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
        "1. Standardize features: Normalize [height, weight, age, blood pressure] (exclude gender if itâ€™s categorical).\n",
        "2. Compute explained variance: Perform PCA and calculate the explained variance ratio for each principal component.\n",
        "3. Choose components: Retain components that explain a cumulative variance of at least 95%.\n",
        "   - Example: If the first 3 components explain 95% of the variance, retain these 3.\n",
        "4. Justification: Reducing dimensionality while preserving most of the information helps reduce noise and computational cost.\n"
      ],
      "metadata": {
        "id": "C-N3QNmhtpKR"
      }
    }
  ]
}